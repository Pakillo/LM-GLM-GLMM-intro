---
title: "Generalised Linear Models: Logistic regression"
output:
  beamer_presentation:
    fig_height: 5
    fig_width: 7
    includes:
      in_header: header.tex
    incremental: yes
    keep_tex: no
    latex_engine: xelatex
fontsize: 10pt
urlcolor: blue
linkcolor: blue
---


```{r include=FALSE, cache=FALSE}

library(rmarkdown)
library(knitr)

### Chunk options ###

## Text results
opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)

## Code decoration
opts_chunk$set(tidy = FALSE, comment = NA, highlight = TRUE, size = "footnotesize")

opts_chunk$set(fig.align = "center") 

opts_chunk$set(cache = TRUE, cache.path = "knitr_cache/")

```


## Q: Survival of passengers on the Titanic ~ Class

Read `titanic_long.csv` dataset and fit linear model (survival ~ class).

\vspace{5mm}

```{r prepare_titanic_data, echo=FALSE, eval=FALSE}
titanic <- read.table("http://www.amstat.org/publications/jse/datasets/titanic.dat.txt")
names(titanic) <- c("class", "age", "sex", "survived")
titanic$class <- factor(titanic$class, labels = c("crew", "first", "second", "third"))
titanic$age <- factor(titanic$age, labels = c("child", "adult"))
titanic$sex <- factor(titanic$sex, labels = c("female", "male"))
write.csv(titanic, file = "data/titanic_long.csv", row.names=FALSE, quote=FALSE)
```

```{r read_titanic, echo=FALSE}
titanic <- read.csv("data/titanic_long.csv")
head(titanic)
```


## Quiz

https://pollev.com/franciscorod726


## Let's check linear model:

```{r titanic_lm, echo=1}
m5 <- lm(survived ~ class, data = titanic)
layout(matrix(1:4, nrow=2))
plot(m5)
dev.off()
```



## Weird residuals!

```{r titanic_lm_resid, echo=FALSE}
hist(resid(m5))
```


## What if your residuals are clearly non-normal, or variance not constant (heteroscedasticity)?

Binary variables (0/1)

\vspace{5mm}

Counts (0, 1, 2, 3, ...)

\vspace{5mm}
Generalised Linear Models to the rescue!


## Generalised Linear Models

1. **Response variable** - distribution `family`
    + Bernouilli - Binomial
    + Poisson
    + Gamma
    + etc

\vspace{3mm}

2. **Predictors** (continuous or categorical)

\vspace{3mm}

3. **Link function**
    + Gaussian: identity
    + Binomial: logit, probit
    + Poisson: log...
    + See [`family`](http://www.rdocumentation.org/packages/stats/functions/family).



## The modelling process

![](images/modeling_process.png)

Bolker 2008



## Bernouilli - Binomial distribution (Logistic regression) 

Response variable: **Yes/No** (e.g. survival, sex, presence/absence)

Link function: `logit` (others possible, see `family`)

$$
  \begin{aligned} 
  logit(p) = \ln \left( \dfrac {p} {1-p}\right) \\ 
  \end{aligned} 
$$

Then

$$
  \begin{aligned} 
  Pr(alive) = a + bx \\  
  logit(Pr(alive)) = a + bx \\  
  Pr(alive) = invlogit(a + bx) = \dfrac {e^{a+bx}} {1+e^{a+bx}} \\  
  \end{aligned} 
$$
  


## Back to survival of Titanic passengers 

How many survived in each class?

\vspace{3mm}

```{r}
table(titanic$class, titanic$survived)
```



## Back to survival of Titanic passengers (dplyr)

Passenger survival according to class

\vspace{3mm}

```{r titanic_dplyr, echo=c(-1)}
library(dplyr)
titanic %>%
  group_by(class, survived) %>%
  summarise(count = n())
```




## Or graphically...

```{r titanic_eda}
plot(factor(survived) ~ factor(class), data = titanic)
```

## Mosaic plots (ggplot2)

\footnotesize

```{r echo=2:3}
library(ggmosaic)
ggplot(titanic) +
  geom_mosaic(aes(x = product(survived, class))) +
  labs(x = "", y = "Survived")
```

\normalsize



## Fitting GLMs in R: `glm`

\small

```{r echo=TRUE}
tit.glm <- glm(survived ~ class, data = titanic, family = binomial)
```

\normalsize

\vspace{3mm}

which corresponds to 

$$
  \begin{aligned}  
  logit(Pr(survival)_{i}) = a + b \cdot class_{i} \\  
  logit(Pr(survival)_{i}) = a + b_{first} + c_{second} + d_{third} \\
  \end{aligned}  
$$



## Fitting GLMs in R: `glm`

\scriptsize
```{r titanic_glm, echo=1}
tit.glm <- glm(survived ~ class, data = titanic, family = binomial)
summary(tit.glm)
```

**These estimates are in logit scale!**

\normalsize

## Interpreting logistic regression output 

Parameter estimates (logit-scale)
```{r tit_glm_coef, echo=FALSE}
coef(tit.glm)
```

\vspace{3mm}

**We need to back-transform**: apply *inverse logit*    

\vspace{3mm}

Crew probability of survival:
```{r tit_glm_invlogit}
plogis(coef(tit.glm)[1])
```

\vspace{3mm}

Looking at the data, the proportion of crew who survived is
```{r crew_surv, echo=FALSE}
sum(titanic$survived[titanic$class == "crew"]) / nrow(titanic[titanic$class == "crew", ])
```


## Q: Probability of survival for 1st class passengers? 

Must add intercept (baseline) to the parameter estimate:
\vspace{3mm}

```{r first_surv}
plogis(coef(tit.glm)[1] + coef(tit.glm)[2])
```

\vspace{3mm}

Again this value matches the data: 
\vspace{3mm}

```{r first_surv_data}
sum(titanic$survived[titanic$class == "first"]) /   
  nrow(titanic[titanic$class == "first", ])
```


## Model interpretation using `effects` package

```{r tit_glm_effects}
library(effects)
allEffects(tit.glm)
```


## Presenting model results

```{r echo=TRUE}
kable(xtable::xtable(tit.glm), digits = 2)
```


## Visualising model: `effects` package

```{r effects_plot}
plot(allEffects(tit.glm))
```


## Visualising model: `visreg` package

```{r echo=2}
library(visreg)
visreg(tit.glm, scale = "response", rug = FALSE)
```


## Visualising model: `sjPlot` package

```{r echo=4}
library(ggplot2)
library(sjPlot)
theme_set(theme_minimal(base_size = 16))
sjPlot::plot_model(tit.glm, type = "eff")
```



## Logistic regression: model checking

\vspace{3mm}

**Not very useful**

```{r tit_glm_check, echo=FALSE}
layout(matrix(1:4, nrow = 2))
plot(tit.glm)
dev.off()
```





## Binned residual plots for logistic regression

```{r binnedplot}
predvals <- predict(tit.glm, type="response")
arm::binnedplot(predvals, titanic$survived - predvals)
```


## Residual diagnostics with DHARMa

```{r echo=TRUE}
library(DHARMa)
simulateResiduals(tit.glm, plot = TRUE)
```

See https://cran.r-project.org/web/packages/DHARMa/vignettes/DHARMa.html


## Model checking with simulated data

```{r out.height="3in", out.width="3.5in"}
library(bayesplot)
sims <- simulate(tit.glm, nsim = 100)
ppc_bars(titanic$survived, yrep = t(as.matrix(sims)))
```


## Pseudo R-squared for GLMs

```{r}
library(performance)
r2(tit.glm)
```

\vspace{5mm}

But many caveats apply! (e.g. see [here](https://stats.stackexchange.com/questions/3559/which-pseudo-r2-measure-is-the-one-to-report-for-logistic-regression-cox-s) and [here](http://data.library.virginia.edu/is-r-squared-useless/))


## Recapitulating


1. **Visualise data**

\vspace{3mm}

2. **Fit model**: `glm`. Don't forget to specify `family`!

\vspace{3mm}

3. **Examine model**: `summary`

\vspace{3mm}

4. **Back-transform parameters** from *logit* into probability scale (e.g. `allEffects`)

\vspace{3mm}

5. **Plot model**: `plot(allEffects(model))`, `visreg`, `plot_model`...

\vspace{3mm}

6. **Examine residuals**: `DHARMa::simulateResiduals`.





# Q: Did men have higher survival than women?

## Quiz

https://pollev.com/franciscorod726


## Plot first

```{r tit_sex_eda}
plot(factor(survived) ~ as.factor(sex), data = titanic)
```

## Fit model

```{r tit_sex, echo=FALSE}
tit.sex <- glm(survived ~ sex, data = titanic, family = binomial)
summary(tit.sex)
```


## Effects

\begincols
\begincol
```{r tit_sex_effects, echo=FALSE}
allEffects(tit.sex)
```
\endcol

\begincol
```{r tit_sex_effects2, echo=FALSE, fig.height=5, fig.width=4}
plot(allEffects(tit.sex))
```
\endcol
\endcols


# Q: Did women have higher survival because they travelled more in first class?


## Let's look at the data

```{r tit_women}
table(titanic$class, titanic$survived, titanic$sex)
```

Mmmm... 


## Quiz

https://pollev.com/franciscorod726


## Fit additive model with both factors 

```{r echo=1}
tit.sex.class <- glm(survived ~ class + sex, family = binomial, data = titanic)
arm::display(tit.sex.class)
```


## Plot additive model

```{r}
plot(allEffects(tit.sex.class))
```



## Fit model with both factors (interactions)

```{r tit_sex_class, echo=1}
tit.sex.class <- glm(survived ~ class * sex, family = binomial, data = titanic)
arm::display(tit.sex.class)
```


## Effects


\begincols
\begincol
```{r tit_sex_class_effects, echo=FALSE}
allEffects(tit.sex.class)
```
\endcol

\begincol
```{r tit_sex_class_effects2, echo=FALSE, fig.height=5, fig.width=4}
plot(allEffects(tit.sex.class))
# visreg(tit.sex.class, by = "sex", xvar = "class")
```
\endcol
\endcols


So, **women had higher probability of survival than men, even within the same class**.

## Effects (sjPlot)

```{r}
plot_model(tit.sex.class, type = "int")
```


## Extra exercises:

Is survival related to age?

Are age effects dependent on sex?



# Logistic regression for proportion data


## Read Titanic data in different format

Read `titanic_prop.csv` data.

\vspace{3mm}

```{r read_tit_short, echo = FALSE}
tit.prop <- read.csv("data/titanic_prop.csv")
head(tit.prop)
```

\vspace{3mm}

These are the same data, but summarized (see `Freq` variable).


## Use cbind(n.success, n.failures) as response

```{r binom_prop, echo=1}
prop.glm <- glm(cbind(Yes, No) ~ Class, data = tit.prop, family = binomial)
summary(prop.glm)
```

## Effects

```{r prop_glm_effects, echo=FALSE}
allEffects(prop.glm)
```

\vspace{5mm}

**Compare with former model based on raw data:**
\vspace{3mm}

```{r comp, echo=FALSE}
allEffects(tit.glm)
```

\vspace{3mm}

Same results!








# Logistic regression with continuous predictors


----

Example dataset: [GDP and infant mortality](http://vincentarelbundock.github.io/Rdatasets/doc/car/UN.html)

\vspace{3mm}

Read `UN_GDP_infantmortality.csv`.

\vspace{3mm}

```{r read_gdp, echo = FALSE}
#gdp <- read.csv("http://vincentarelbundock.github.io/Rdatasets/csv/car/UN.csv")
gdp <- read.csv("data/UN_GDP_infantmortality.csv")
names(gdp) <- c("country", "mortality", "gdp")
summary(gdp)
```


## Q: Is infant mortality related to GDP?

https://pollev.com/franciscorod726


## EDA

```{r gdp_eda}
plot(mortality ~ gdp, data = gdp, main = "Infant mortality (per 1000 births)")
```


## Fit model

```{r gdp_glm, echo=1}
gdp.glm <- glm(cbind(mortality, 1000 - mortality) ~ gdp, 
               data = gdp, family = binomial)
summary(gdp.glm)
```


## Effects

```{r gdp_effects}
allEffects(gdp.glm)
```

## Effects plot

```{r gdp_effectsplot}
plot(allEffects(gdp.glm))
```





## Plot model using visreg:

```{r gdp_visreg, echo=c(2,3)}
library(visreg)
visreg(gdp.glm, scale = "response")
points(mortality/1000 ~ gdp, data = gdp)
```


## Residuals diagnostics with DHARMa

```{r echo=TRUE}
simulateResiduals(gdp.glm, plot = TRUE)
```




# Overdispersion


## Testing for overdispersion (DHARMa)

```{r echo = TRUE}
simres <- simulateResiduals(gdp.glm, refit = TRUE)
testDispersion(simres, plot = FALSE)
```


## Overdispersion in logistic regression with proportion data

```{r logreg_overdisp, echo=1}
gdp.overdisp <- glm(cbind(mortality, 1000 - mortality) ~ gdp, 
               data = gdp, family = quasibinomial)
summary(gdp.overdisp)
```


## Mean estimates do not change after accounting for overdispersion

```{r logreg_overdisp2, echo=FALSE}
allEffects(gdp.overdisp)
allEffects(gdp.glm)
```



## But standard errors (uncertainty) do!

\begincols
\begincol
```{r overdisp_eff1, echo=FALSE, fig.height=5, fig.width=4}
plot(allEffects(gdp.overdisp))
```
\endcol

\begincol
```{r overdisp_eff2, echo=FALSE, fig.height=5, fig.width=4}
plot(allEffects(gdp.glm))
```
\endcol
\endcols





## Plot model and data

\begincols
\begincol

```{r overdisp_plot1, echo=FALSE, fig.height=5, fig.width=4}
visreg(gdp.glm, scale = "response", main = "Binomial")
points(mortality/1000 ~ gdp, data = gdp, pch = 20)
```
\endcol

\begincol

```{r overdisp_plot2, echo=FALSE, fig.height=5, fig.width=4}
visreg(gdp.overdisp, scale = "response", main = "Quasibinomial")
points(mortality/1000 ~ gdp, data = gdp, pch = 20)
```
\endcol
\endcols



## Overdispersion

Whenever you fit logistic regression to **proportion** data, check family `quasibinomial`.



## Think about the shape of relationships

y ~ x + z

Really? Not everything has to be linear! Actually, it often is not.

**Think** about shape of relationship. See chapter 3 in Bolker's book.


\begincols

\begincol

```{r echo=FALSE}
curve(0.7 + 0.3*x, ylab="y", las=1)
```

\endcol

\begincol

```{r echo=FALSE}
curve(0.7*x^0.3, ylab="y", las=1)
```

\endcol

\endcols



## Think about the shape of relationships

```{r}
visreg(gdp.glm, ylab = "Mortality (logit scale)")
```


## Think about the shape of relationships

```{r echo=FALSE}
library(ggResidpanel)
resid_panel(gdp.glm)
```



## Think about the shape of relationships

\begincols
\begincol

```{r echo=FALSE, fig.height=5, fig.width=4}
visreg(gdp.overdisp, main = "Mortality ~ GDP", ylab = "Mortality (logit scale)")
```
\endcol

\begincol

```{r echo=FALSE, fig.height=5, fig.width=4}
gdp.overdisp2 <- glm(cbind(mortality, 1000 - mortality) ~ gdp + I(gdp*gdp), 
               data = gdp, family = quasibinomial)
visreg(gdp.overdisp2, main = "Mortality ~ GDP + GDP^2", ylab = "Mortality (logit scale)")
```
\endcol
\endcols



## Think about the shape of relationships

\begincols
\begincol

```{r echo=FALSE, fig.height=5, fig.width=4}
visreg(gdp.overdisp, main = "Mortality ~ GDP", scale = "response", ylab = "Mortality")
points(mortality/1000 ~ gdp, data = gdp, pch = 20)
```
\endcol

\begincol

```{r echo=FALSE, fig.height=5, fig.width=4}
gdp.overdisp2 <- glm(cbind(mortality, 1000 - mortality) ~ gdp + I(gdp*gdp), 
               data = gdp, family = quasibinomial)
visreg(gdp.overdisp2, main = "Mortality ~ GDP + GDP^2", scale = "response", ylab = "Mortality")
points(mortality/1000 ~ gdp, data = gdp, pch = 20)
```
\endcol
\endcols



## Think about the shape of relationships

\begincols
\begincol

```{r echo=FALSE, fig.height=5, fig.width=4}
visreg(gdp.overdisp, main = "Mortality ~ GDP", ylab = "Mortality (logit scale)")
```
\endcol

\begincol

```{r echo=FALSE, fig.height=5, fig.width=4}
gdp.overdisp2 <- glm(cbind(mortality, 1000 - mortality) ~ log(gdp), 
               data = gdp, family = quasibinomial)
visreg(gdp.overdisp2, main = "Mortality ~ log(GDP)", ylab = "Mortality (logit scale)")
```
\endcol
\endcols



## Think about the shape of relationships

\begincols
\begincol

```{r echo=FALSE, fig.height=5, fig.width=4}
visreg(gdp.overdisp, main = "Mortality ~ GDP", scale = "response", ylab = "Mortality")
points(mortality/1000 ~ gdp, data = gdp, pch = 20)
```
\endcol

\begincol

```{r echo=FALSE, fig.height=5, fig.width=4}
gdp.overdisp2 <- glm(cbind(mortality, 1000 - mortality) ~ log(gdp), 
               data = gdp, family = quasibinomial)
visreg(gdp.overdisp2, main = "Mortality ~ log(GDP)", scale = "response", ylab = "Mortality")
points(mortality/1000 ~ gdp, data = gdp, pch = 20)
```
\endcol
\endcols




```{r echo=2, eval=FALSE}
## Think about the shape of relationships
gdp.log <- glm(cbind(mortality, 1000 - mortality) ~ log(gdp), 
               data = gdp, family = quasibinomial)
resid_panel(gdp.log)
```



```{r eval=FALSE, echo=FALSE}
## Trying Poisson
m <- glm(mortality ~ log(gdp), data = gdp, family = quasipoisson)
summary(m)
visreg(m, scale = "response")
points(mortality ~ gdp, data = gdp)
```


## More examples

- seedset.csv: Comparing seed set among plants (Data from [Harder et al. 2011](https://datadryad.org/resource/doi:10.5061/dryad.0vf86nb1.2))



## Seed set among plants

```{r}
seed <- readr::read_csv("data/seedset.csv")
head(seed)
seed$plant <- as.factor(seed$plant)
```

## Questions:

https://pollev.com/franciscorod726
\vspace{5mm}

- Is seed set related to proportion of outcross pollen (pcmass)?

\vspace{5mm}

- Which plant had lower seed set?





## Number of seeds vs Number of ovules

```{r}
plot(seeds ~ ovulecnt, data = seed)
```


## Number of seeds vs Proportion outcross pollen

```{r}
plot(seeds ~ pcmass, data = seed)
```

## Seed set across plants

```{r echo=FALSE}
seedm <- glm(cbind(seeds, ovulecnt - seeds) ~ plant, data = seed, family = binomial)
#summary(seedm)
plot(allEffects(seedm))
```


## Seed set ~ outcross pollen

```{r echo=FALSE}
seedm <- glm(cbind(seeds, ovulecnt - seeds) ~ plant + pcmass, data = seed, family = binomial)
#summary(seedm)
plot(allEffects(seedm))
```

